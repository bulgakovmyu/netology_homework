{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:58:48.876209Z",
     "start_time": "2020-08-03T20:58:48.869207Z"
    }
   },
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans, SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split as train_test_split_s\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гибридная рекомендательная система\n",
    "Я решил попробовать сделать рекомендательную систему каскадного типа с примесью блендинга.\n",
    "Первой моделью я выбираю 20 наиболее подходящих рекомендаций, второй моделью их ранжирую другим способом, и в итоге смешиваю результат, отдавая большее предпочтение второй модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:58:13.529580Z",
     "start_time": "2020-08-03T20:58:13.525580Z"
    }
   },
   "source": [
    "данные для обучения первой модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:58:51.111447Z",
     "start_time": "2020-08-03T20:58:50.005206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (100836, 6)\n",
      "users: 610\n",
      "items: 9724\n"
     ]
    }
   ],
   "source": [
    "    movies = pd.read_csv('D:/GitRepo/Нетология/Рекомендательные системы/netology-recsys-master/netology-recsys-master/lecture-1/movies.csv')\n",
    "    ratings = pd.read_csv('D:/GitRepo/Нетология/Рекомендательные системы/netology-recsys-master/netology-recsys-master/lecture-1/ratings.csv')\n",
    "    \n",
    "    movies_with_ratings = movies.join(ratings.set_index('movieId'), on='movieId').reset_index(drop=True)\n",
    "    movies_with_ratings.dropna(inplace=True)\n",
    "    \n",
    "    print('shape', movies_with_ratings.shape)\n",
    "    \n",
    "    dataset = pd.DataFrame({\n",
    "        'uid': movies_with_ratings.userId,\n",
    "        'iid': movies_with_ratings.movieId,\n",
    "        'rating': movies_with_ratings.rating\n",
    "    })\n",
    "    \n",
    "    print('users:', len(dataset.uid.unique()))\n",
    "    print('items:',len(dataset.iid.unique()))\n",
    "    \n",
    "    \n",
    "    r_min = ratings.rating.min()\n",
    "    r_max = ratings.rating.max()\n",
    "    \n",
    "    reader = Reader(rating_scale=(r_min, r_max))\n",
    "    data = Dataset.load_from_df(dataset, reader)\n",
    "    \n",
    "    trainset, testset = train_test_split(data, test_size=.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая модель - SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:59:41.441606Z",
     "start_time": "2020-08-03T20:59:38.452930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x209e808c550>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(n_factors=20, n_epochs=30)\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T20:59:41.603643Z",
     "start_time": "2020-08-03T20:59:41.442607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8695282854721408"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = algo.test(testset)\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:00:45.378309Z",
     "start_time": "2020-08-03T21:00:45.373307Z"
    }
   },
   "source": [
    "Вторая модель - линейное предсказание оценки, используя разные фичи фильмов и пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:00:50.056246Z",
     "start_time": "2020-08-03T21:00:50.053245Z"
    }
   },
   "outputs": [],
   "source": [
    "def change_string(s):\n",
    "    return ' '.join(str(s).replace(' ', '').replace('-', '').split('|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем и преобразовываем данные для обучения второй модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:00:52.342494Z",
     "start_time": "2020-08-03T21:00:50.886167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---10---\n",
      "---9---\n",
      "---8---\n",
      "---7---\n",
      "---6---\n",
      "---5---\n",
      "---4---\n",
      "---3---\n",
      "---2---\n",
      "---1---\n",
      "---0---\n"
     ]
    }
   ],
   "source": [
    "    movies = pd.read_csv('D:/GitRepo/Нетология/Рекомендательные системы/netology-recsys-master/netology-recsys-master/lecture-1/movies.csv')\n",
    "    print('---10---')\n",
    "    ratings = pd.read_csv('D:/GitRepo/Нетология/Рекомендательные системы/netology-recsys-master/netology-recsys-master/lecture-1/ratings.csv')\n",
    "    print('---9---')\n",
    "    tags = pd.read_csv('D:/GitRepo/Нетология/Рекомендательные системы/netology-recsys-master/netology-recsys-master/lecture-1/tags.csv')\n",
    "    print('---8---')\n",
    "    # Users\n",
    "    df_1 = ratings[['userId', 'movieId', 'rating']]\n",
    "    df_1_1 = pd.DataFrame(df_1.groupby('userId').rating.mean()).rename(columns={'rating': 'user_mean_rating'})\n",
    "    df_1_1 = pd.merge(df_1_1, pd.DataFrame(df_1.groupby('userId').rating.median()).rename(columns={'rating': 'user_median_rating'}),\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "    df_1_1 = pd.merge(df_1_1, pd.DataFrame(df_1.groupby('userId').rating.var()).rename(columns={'rating': 'user_variance_rating'}),\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "    df_1_1 = pd.merge(df_1_1, pd.DataFrame(df_1.groupby('userId').rating.max()).rename(columns={'rating': 'user_max_rating'}),\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "    df_1_1 = pd.merge(df_1_1, pd.DataFrame(df_1.groupby('userId').rating.min()).rename(columns={'rating': 'user_min_rating'}),\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "    print('---7---')\n",
    "    \n",
    "    # Movies\n",
    "    df_1_2 = pd.DataFrame(df_1.groupby('movieId').rating.mean()).rename(columns={'rating': 'movie_mean_rating'})\n",
    "    df_1_2 = pd.merge(df_1_2, pd.DataFrame(df_1.groupby('movieId').rating.median()).rename(columns={'rating': 'movie_median_rating'}),\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "    df_1_2 = pd.merge(df_1_2, pd.DataFrame(df_1.groupby('movieId').rating.var()).rename(columns={'rating': 'movie_variance_rating'}),\n",
    "             left_index=True,\n",
    "             right_index=True).fillna(0)\n",
    "    df_1_2 = pd.merge(df_1_2, pd.DataFrame(df_1.groupby('movieId').rating.max()).rename(columns={'rating': 'movie_max_rating'}),\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "    df_1_2 = pd.merge(df_1_2, pd.DataFrame(df_1.groupby('movieId').rating.min()).rename(columns={'rating': 'movie_min_rating'}),\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "    print('---6---')\n",
    "    \n",
    "    # GENRES\n",
    "    df_2 = movies[['movieId', 'genres']]\n",
    "    movie_genres = [change_string(g) for g in df_2.genres.values]\n",
    "    count_vect = CountVectorizer()\n",
    "    buffer = count_vect.fit_transform(movie_genres)\n",
    "    tfidf_transformer  = TfidfTransformer()\n",
    "    buffer = tfidf_transformer.fit_transform(buffer)\n",
    "    df_2 = pd.DataFrame(buffer.toarray(), columns=count_vect.get_feature_names())\n",
    "    df_2 = pd.merge(movies[['movieId']], df_2, how='left', left_index=True, right_index=True)\n",
    "    df_2.index = df_2.movieId\n",
    "    df_2.drop(columns=['movieId'], inplace=True)\n",
    "    df_2.fillna(0.0, inplace=True)\n",
    "    print('---5---')\n",
    "    \n",
    "    # TAGS\n",
    "    movie_gtags = [change_string(g) for g in tags.tag.values]\n",
    "    count_vect = CountVectorizer()\n",
    "    buffer = count_vect.fit_transform(movie_gtags)\n",
    "    buffer1 = pd.DataFrame(buffer.toarray(), columns=count_vect.get_feature_names())\n",
    "    common_tags = buffer1.sum().sort_values(ascending=False)[buffer1.sum().sort_values(ascending=False) > 5].index\n",
    "    tfidf_transformer  = TfidfTransformer()\n",
    "    buffer = tfidf_transformer.fit_transform(buffer)\n",
    "    df_3 = pd.DataFrame(buffer.toarray(), columns=count_vect.get_feature_names())\n",
    "    df_3 = df_3[common_tags]\n",
    "    df_3 = pd.merge(movies[['movieId']], df_3, how='left', left_index=True, right_index=True)\n",
    "    df_3.index = df_3.movieId\n",
    "    df_3.drop(columns=['movieId'], inplace=True)\n",
    "    df_3.fillna(0.0, inplace=True)\n",
    "    print('---4---')\n",
    "    \n",
    "    # final dataset     \n",
    "    df = ratings[['userId', 'movieId', 'rating']]\n",
    "    df = pd.merge(df, df_1_1, how='left', left_on='userId', right_index=True)\n",
    "    df = pd.merge(df, df_1_2, how='left', left_on='movieId', right_index=True)\n",
    "    df = pd.merge(df, df_2, how='left', left_on='movieId', right_index=True)\n",
    "    df = pd.merge(df, df_3, how='left', left_on='movieId', right_index=True)\n",
    "    print('---3---')\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "    print('---2---')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split_s(X.drop(columns=['rating']), \n",
    "                                                        X['rating'], \n",
    "                                                        test_size=0.1)\n",
    "    print('---1---')\n",
    "    print('---0---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:05:32.583377Z",
     "start_time": "2020-08-03T21:01:38.005513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=18.1, copy_X=True, fit_intercept=True, max_iter=10000,\n",
       "      normalize=False, random_state=None, solver='lsqr', tol=0.001)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'alpha':list(np.arange(0.1, 100.0, 0.1)),\n",
    "          'max_iter':[500, 1000, 2000, 5000, 10000],\n",
    "          'tol':[1e-3, 1e-2, 1e-4, 1e-5],\n",
    "          'solver':['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']          \n",
    "          }\n",
    "linear_model = RandomizedSearchCV(Ridge(), params, cv=10, random_state=13, n_iter=10)\n",
    "linear_model = linear_model.fit(X_train,y_train).best_estimator_\n",
    "linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:05:54.576494Z",
     "start_time": "2020-08-03T21:05:54.566493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7752806599372357\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', mean_squared_error(y_test, linear_model.predict(X_test), squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:05:32.589378Z",
     "start_time": "2020-08-03T21:05:32.585378Z"
    }
   },
   "source": [
    "Предсказываем 5 рекомендованных фильмов для пользователя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:17:40.059117Z",
     "start_time": "2020-08-03T21:17:40.047114Z"
    }
   },
   "outputs": [],
   "source": [
    "def recomendation_for_user(user_id):\n",
    "    user_movies = df[df.userId == user_id].movieId.unique()\n",
    "    m = df[~df.movieId.isin(user_movies)][movie_features+['movieId']].drop_duplicates()\n",
    "    m['userId'] = user_id\n",
    "    m['rating'] = 0\n",
    "\n",
    "    m = pd.merge(m, df[df.userId==user_id][user_features+['userId']].drop_duplicates(), how='left', left_on='userId', right_on='userId')\n",
    "    m = m[X.columns]\n",
    "    to_model = pd.DataFrame(scaler.transform(m), columns=m.columns)\n",
    "\n",
    "    res_1 = pd.concat([to_model.drop(columns=['rating']), pd.Series(linear_model.predict(to_model.drop(columns=['rating'])), name='rating')], axis=1)\n",
    "\n",
    "    res_1 = pd.DataFrame(scaler.inverse_transform(res_1[X.columns]), columns=X.columns).sort_values('rating', ascending=False).head(20)[['movieId','rating']].reset_index(drop=True)\n",
    "\n",
    "    rats = []\n",
    "    for mov in res_1.movieId:\n",
    "        rats.append({'movieId': algo.predict(uid=user_id, iid=mov).iid,\n",
    "                    'rating': algo.predict(uid=user_id, iid=mov).est})\n",
    "    res_2 = pd.merge(res_1, pd.DataFrame(rats), how='left', left_on='movieId', right_on='movieId')\n",
    "\n",
    "    res_2['rating_z'] = (res_2['rating_x']/5 + res_2['rating_y']/3)\n",
    "    recommendation = res_2.sort_values('rating_z', ascending=False).head(5).movieId\n",
    "#     print(recommendation)\n",
    "    for n,i in enumerate(recommendation):\n",
    "        print(n+1,':',movies[movies.movieId==i].title.iloc[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем для трех разных пользователей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:17:41.312401Z",
     "start_time": "2020-08-03T21:17:40.671256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : Jonah Who Will Be 25 in the Year 2000 (Jonas qui aura 25 ans en l'an 2000) (1976)\n",
      "2 : Babes in Toyland (1934)\n",
      "3 : Unfaithfully Yours (1948)\n",
      "4 : Calcium Kid, The (2004)\n",
      "5 : Denise Calls Up (1995)\n"
     ]
    }
   ],
   "source": [
    "recomendation_for_user(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:17:42.461682Z",
     "start_time": "2020-08-03T21:17:41.854544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : Jonah Who Will Be 25 in the Year 2000 (Jonas qui aura 25 ans en l'an 2000) (1976)\n",
      "2 : Unfaithfully Yours (1948)\n",
      "3 : Siam Sunset (1999)\n",
      "4 : Calcium Kid, The (2004)\n",
      "5 : Satin Rouge (2002)\n"
     ]
    }
   ],
   "source": [
    "recomendation_for_user(50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-03T21:17:43.492913Z",
     "start_time": "2020-08-03T21:17:42.854768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : Jonah Who Will Be 25 in the Year 2000 (Jonas qui aura 25 ans en l'an 2000) (1976)\n",
      "2 : Go for Zucker! (Alles auf Zucker!) (2004)\n",
      "3 : Sorority House Massacre II (1990)\n",
      "4 : Babes in Toyland (1934)\n",
      "5 : Denise Calls Up (1995)\n"
     ]
    }
   ],
   "source": [
    "recomendation_for_user(550.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, безусловно в работе этой системы есть странности (например почему-то на первом месте в рекомендации дается один фильм и подобное). Но эта модель и не претендует на что-то суперкачественное :) \n",
    "Но в качестве модельной гибридной системы, думаю, подойдет :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
